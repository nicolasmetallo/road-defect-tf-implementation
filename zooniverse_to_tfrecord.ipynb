{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zooniverse-to-tfrecord",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nicolasmetallo/road-defect-tf-implementation/blob/master/zooniverse_to_tfrecord.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "d4qIipCmZKzC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download data from Zooniverse and convert to TFRecord\n",
        "\n",
        "---\n",
        "**Author:** Nicolas Metallo & Cristian Belussi. Last updated on August 15, 2018.\n",
        "\n",
        "This page walks through the steps required to train an object detection model on a local machine. It assumes the reader has completed the following prerequisites:\n",
        "\n",
        "- The Tensorflow Object Detection API\n",
        "- A valid data set has been created. See this page for instructions on how to generate a dataset for the PASCAL VOC challenge or the Oxford-IIIT Pet dataset.\n",
        "- A Object Detection pipeline configuration has been written. See this page for details on how to write a pipeline configuration."
      ]
    },
    {
      "metadata": {
        "id": "kCW4hXEAf_Mc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# *1) Clone GitHub, download images from Zooniverse, and import annotation data*\n",
        "\n",
        "---\n",
        "\n",
        "Source: https://github.com/Streets-Data-Collaborative/squid-vision/tree/master/tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "NxjY5OPqcQTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#=============== Import Libraries ===============#\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "#=============== Git Clone ===============#\n",
        "!git clone https://github.com/nicolasmetallo/road-defect-tf-implementation.git\n",
        "home_dir = \"/content\"\n",
        "os.chdir(os.path.join(home_dir, \"road-defect-tf-implementation\"))\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "#=============== Split 'images' into train, val, test ===============#\n",
        "!python3 build_dataset.py --data_dir='images' --output_dir='images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCf-E84utO9F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# *2) Extract annotation, image label, and labelmap (.pbtxt) data and save into csv*\n",
        "\n",
        "---\n",
        "\n",
        "Source: https://storage.googleapis.com/openimages/web/download.html\n",
        "\n",
        "## Data Formats\n",
        "### Bounding Boxes\n",
        "Each row defines one bounding box.\n",
        "\n",
        "```\n",
        "ImageID,Label,XMin,XMax,YMin,YMax\n",
        "000026e7ee790996,/m/07j7r,0.071905,0.145346,0.206591,0.391306\n",
        "000026e7ee790996,/m/07j7r,0.439756,0.572466,0.264153,0.435122\n",
        "000026e7ee790996,/m/07j7r,0.668455,1.000000,0.000000,0.552825\n",
        "000062a39995e348,/m/015p6,0.205719,0.849912,0.154144,1.000000\n",
        "000062a39995e348,/m/05s2s,0.137133,0.377634,0.000000,0.884185\n",
        "0000c64e1253d68f,/m/07yv9,0.000000,0.973850,0.000000,0.043342\n",
        "0000c64e1253d68f,/m/0k4j,0.000000,0.513534,0.321356,0.689661\n",
        "0000c64e1253d68f,/m/0k4j,0.016515,0.268228,0.299368,0.462906\n",
        "0000c64e1253d68f,/m/0k4j,0.481498,0.904376,0.232029,0.489017\n",
        "```\n",
        "#### ImageID: \n",
        "The image this box lives in.\n",
        "\n",
        "#### Label: \n",
        "The object class this box belongs to.\n",
        "\n",
        "#### XMin, XMax, YMin, YMax: \n",
        "Coordinates of the box, in normalized image coordinates. XMin is in [0,1], where 0 is the leftmost pixel, and 1 is the rightmost pixel in the image. Y coordinates go from the top pixel (0) to the bottom pixel (1).\n",
        "\n",
        "Circular annotations will be turned into rectangular annotations by adding and substranging the radius to (x,y) coordinates, e.g. Xmin = x-r\n",
        "\n",
        "![alt text](https://i.stack.imgur.com/53E6N.png)\n",
        "\n",
        "### Class Names\n",
        "The class names in MID format can be converted to their short descriptions by looking into class-descriptions.csv:\n",
        "\n",
        "```\n",
        "/m/0pc9,Alphorn\n",
        "/m/0pckp,Robin\n",
        "/m/0pcm_,Larch\n",
        "/m/0pcq81q,Soccer player\n",
        "/m/0pcr,Alpaca\n",
        "/m/0pcvyk2,Nem\n",
        "/m/0pd7,Army\n",
        "/m/0pdnd2t,Bengal clockvine\n",
        "/m/0pdnpc9,Bushwacker\n",
        "/m/0pdnsdx,Enduro\n",
        "/m/0pdnymj,Gekkonidae\n",
        "```\n",
        "Note the presence of characters like commas and quotes. The file follows standard CSV escaping rules. e.g.:\n",
        "\n",
        "```\n",
        "/m/02wvth,\"Fiat 500 \"\"topolino\"\"\"\n",
        "/m/03gtp5,Lamb's quarters\n",
        "/m/03hgsf0,\"Lemon, lime and bitters\"\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "dt8qnDTCkzvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#=============== Import Annotation Data ===============#\n",
        "data = pd.read_csv('street-quality-identification-device-syr-classifications.csv') # csv export from Zooniverse\n",
        "split = [\"train\",\"val\"]\n",
        "\n",
        "#=============== Write DataFrame & Save to CSV ===============#\n",
        "\n",
        "# DEFAULT_COLUMNS = ['image_id', 'xmin', 'ymin', 'xmax', 'ymax', 'label']\n",
        "\n",
        "for each in split:\n",
        "  images = []\n",
        "  imageList = glob.glob(os.path.join(os.getcwd(),\"images\",each,\"*.jpg\"))\n",
        "  \n",
        "  for image in range(len(imageList)):\n",
        "    images.append(imageList[image].split('/')[5])\n",
        "    \n",
        "  row_data = {}\n",
        "  df_list = []\n",
        "    \n",
        "  for index in range(len(data)):\n",
        "    imageDict = json.loads(data.subject_data[index])\n",
        "    imageName = str(list(imageDict.values())[0]['Filename'])\n",
        "    \n",
        "    if imageName in images:\n",
        "      annotation = list(json.loads(data.annotations[index]))[0]['value']\n",
        "      for bbox in range(len(annotation)):\n",
        "        try:\n",
        "          r = int(annotation[bbox]['r'])\n",
        "        except:\n",
        "          continue\n",
        "        x = int(annotation[bbox]['x'])\n",
        "        y = int(annotation[bbox]['y'])\n",
        "        label = annotation[bbox]['tool_label']\n",
        "      \n",
        "        row_data = {\"image_id\": str(imageName.replace(\".jpg\",\"\")), \"label\": label.split()[0], \"xmin\": int(x-r), \"xmax\": int(x+r), \"ymin\": int(y-r), \"ymax\": int(y+r)}\n",
        "        df_list.append(row_data)\n",
        "        \n",
        "  bbox_data = pd.DataFrame(df_list)\n",
        "  bbox_data = bbox_data[['image_id', 'xmin', 'ymin', 'xmax', 'ymax', 'label']]\n",
        "  bbox_data.loc[bbox_data.xmin < 0, \"xmin\"] = 0\n",
        "  bbox_data.loc[bbox_data.ymin < 0, \"ymin\"] = 0\n",
        "  \n",
        "  bbox_data.to_csv(os.path.join(os.getcwd(),\"images\",each,\"labels.csv\"), index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nt0sCLyof2s0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# *3) Review image with bounding boxes*\n",
        "\n",
        "---\n",
        "\n",
        "Source: https://www.kaggle.com/alekseit/simple-bounding-boxes"
      ]
    },
    {
      "metadata": {
        "id": "ddHnEGuXYZKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#=============== Visualize annotated images ===============#\n",
        "def visualize_annotated_bbox(index, split = 'train'):\n",
        "  bbox_data = pd.read_csv(os.path.join(os.getcwd(),\"images\",split,\"labels.csv\"))\n",
        "  images_dir = os.path.join(os.getcwd(),\"images\",split)\n",
        "  if index > len(bbox_data):\n",
        "    print(\"Choose a smaller index. Max is {}\".format(len(bbox_data)))\n",
        "    return\n",
        "  img = cv2.imread(os.path.join(images_dir,str(bbox_data.loc[index][\"image_id\"])+\".jpg\"))\n",
        "  color = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  #im = Image.open(images_dir + imageName)\n",
        "  #width, height = im.size\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(color)\n",
        "  rect = Rectangle((bbox_data.loc[index][\"xmin\"],bbox_data.loc[index][\"ymin\"]),(bbox_data.loc[index][\"xmax\"]-bbox_data.loc[index][\"xmin\"]),(bbox_data.loc[index][\"ymax\"]-bbox_data.loc[index][\"ymin\"]), fill=False, color=\"red\")\n",
        "\n",
        "  plt.axes().add_patch(rect)\n",
        "  plt.title('Label = {}'.format(bbox_data.loc[index][\"label\"]))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IfQA4FcIbL87",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# *4) Convert images to TFRecord*\n",
        "\n",
        "---\n",
        "\n",
        "Source: \n",
        "- https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md\n",
        "- https://riemenschneider.hayko.at/vision/dataset/"
      ]
    },
    {
      "metadata": {
        "id": "cURIFfm_uFV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#=============== Convert using Luminoth (https://luminoth.ai) ===============#\n",
        "!pip install luminoth\n",
        "!lumi dataset transform --type csv --data-dir images --output-dir output_dir --split train --split val"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}